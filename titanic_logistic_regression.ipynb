{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3143e28a",
   "metadata": {},
   "source": [
    "# Análisis y Modelo de Regresión Logística — Titanic\n",
    "\n",
    "Este notebook realiza un análisis paso a paso y entrena un **modelo de regresión logística** para predecir la supervivencia en el dataset del Titanic.\n",
    "\n",
    "Se incluyen: descripción de valores faltantes, estrategias de imputación, codificación de variables categóricas, entrenamiento del modelo y evaluación (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d102fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Importaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"Librerías importadas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4af2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (891, 12)\n",
      "Test shape: (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar datasets (asegúrate que train.csv y test.csv estén en el mismo directorio)\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fed04f",
   "metadata": {},
   "source": [
    "## a) Relevamiento de valores faltantes\n",
    "\n",
    "A continuación se muestra la cantidad de valores faltantes por variable para `train` y `test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b89b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de valores faltantes\n",
    "missing_train = train.isnull().sum().sort_values(ascending=False)\n",
    "missing_test = test.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Valores faltantes - train:\\n\", missing_train[missing_train>0])\n",
    "print(\"\\nValores faltantes - test:\\n\", missing_test[missing_test>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d07dbd",
   "metadata": {},
   "source": [
    "## b) Estrategia para completar valores faltantes\n",
    "\n",
    "- **Age**: imputaremos con la mediana (agrupando por `Sex` y `Pclass` para ser más precisos).\n",
    "- **Fare**: imputación por la mediana (solo aparece 1 faltante en test).\n",
    "- **Cabin**: extraeremos la letra del camarote (Deck). Para los valores faltantes usaremos un valor 'M' (Missing).\n",
    "- **Embarked**: imputar con la moda (valor más frecuente).\n",
    "\n",
    "Usaremos un `ColumnTransformer` y un `Pipeline` para encadenar imputación, codificación y escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering: extraer 'Deck' desde 'Cabin' y 'Title' desde 'Name'\n",
    "def extract_deck(cabin):\n",
    "    if pd.isna(cabin):\n",
    "        return 'M'  # Missing\n",
    "    return str(cabin)[0]\n",
    "\n",
    "def extract_title(name):\n",
    "    # extrae título desde el nombre (Mr., Mrs., Miss., etc.)\n",
    "    if pd.isna(name):\n",
    "        return 'Unknown'\n",
    "    parts = name.split(',')\n",
    "    if len(parts) > 1:\n",
    "        title_section = parts[1]\n",
    "        title = title_section.split('.')[0].strip()\n",
    "        return title\n",
    "    return 'Unknown'\n",
    "\n",
    "train['Deck'] = train['Cabin'].apply(extract_deck)\n",
    "test['Deck'] = test['Cabin'].apply(extract_deck)\n",
    "\n",
    "train['Title'] = train['Name'].apply(extract_title)\n",
    "test['Title'] = test['Name'].apply(extract_title)\n",
    "\n",
    "# Mostrar algunas filas\n",
    "train[['Name','Title','Cabin','Deck']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335494",
   "metadata": {},
   "source": [
    "### Preparación de variables para el modelo\n",
    "Seleccionaremos estas features: `Pclass`, `Sex`, `Age`, `SibSp`, `Parch`, `Fare`, `Embarked`, `Deck`, `Title`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd347085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables a usar\n",
    "features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Deck','Title']\n",
    "target = 'Survived'\n",
    "\n",
    "X = train[features].copy()\n",
    "y = train[target].copy()\n",
    "X_test = test[features].copy()\n",
    "\n",
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb049865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones por tipo de variable\n",
    "numeric_features = ['Age','SibSp','Parch','Fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Pclass','Sex','Embarked','Deck','Title']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b042a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline completo con regresión logística\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Dividir en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Entrenar\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en conjunto de validación\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy en validación: {accuracy:.4f}')\n",
    "\n",
    "# Matriz de confusión y reporte\n",
    "print('\\nMatriz de confusión:')\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print('\\nReporte de clasificación:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación adicional con cross-validation (5 folds)\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print('Cross-val accuracy (5 folds):', cv_scores)\n",
    "print('Media CV accuracy: {:.4f} (+/- {:.4f})'.format(cv_scores.mean(), cv_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd7776",
   "metadata": {},
   "source": [
    "#### Nota sobre la imputación de `Age`\n",
    "Además de la imputación por mediana global usada en el pipeline, una alternativa es imputar `Age` usando la mediana por `Sex` y `Pclass`. A continuación se muestra cómo hacerlo y volver a entrenar si se desea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575ee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación avanzada de Age por Sex + Pclass (opcional)\n",
    "X_adv = X.copy()\n",
    "X_adv['Age'] = X_adv.groupby(['Sex','Pclass'])['Age'].apply(lambda grp: grp.fillna(grp.median()))\n",
    "\n",
    "# Si aún quedan NaN (grupos sin datos), llenar con mediana global\n",
    "X_adv['Age'] = X_adv['Age'].fillna(X_adv['Age'].median())\n",
    "\n",
    "# Re-entrenar un modelo rápido para comparar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model_adv = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # preprocessor rellenará numicamente Age si queda NaN\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "scores_adv = cross_val_score(model_adv, X_adv, y, cv=5, scoring='accuracy')\n",
    "print('CV accuracy con imputación por grupo (5 folds):', scores_adv)\n",
    "print('Media:', scores_adv.mean(), 'Std:', scores_adv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc8da0",
   "metadata": {},
   "source": [
    "## Predicción sobre el set `test` y guardado de archivo de salida\n",
    "El dataset `test.csv` no contiene la columna `Survived`. Por eso medimos accuracy usando una partición del `train`. De todas formas generaremos predicciones sobre `test` y las guardaremos en `submission.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b37c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reentrenar el modelo con todo el set de train\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predecir sobre test\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test['PassengerId'],\n",
    "    'Survived': test_preds\n",
    "})\n",
    "\n",
    "output_path = '/mnt/data/submission_titanic_logreg.csv'\n",
    "submission.to_csv(output_path, index=False)\n",
    "print('Archivo de predicción guardado en:', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a14e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar modelo entrenado para uso posterior\n",
    "model_path = '/mnt/data/titanic_logreg_pipeline.joblib'\n",
    "joblib.dump(model, model_path)\n",
    "print('Pipeline guardado en:', model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef032f89",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- Se completaron los valores faltantes con estrategias razonables (medianas y modas).\n",
    "- Se entrenó un primer modelo de regresión logística.\n",
    "- Se reportó el accuracy en un conjunto de validación y con validación cruzada.\n",
    "\n",
    "Si querés, puedo:\n",
    "- Probar otras técnicas de imputación (KNNImputer, tasa de missing indicator, etc.).\n",
    "- Probar otros modelos (Random Forest, XGBoost) y comparar métricas.\n",
    "- Afinar hiperparámetros con GridSearchCV o RandomizedSearchCV.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
